{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9cdd436",
      "metadata": {
        "id": "c9cdd436"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/data.zip"
      ],
      "metadata": {
        "id": "hIzbGH_pYJA-"
      },
      "id": "hIzbGH_pYJA-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e776eafb",
      "metadata": {
        "id": "e776eafb"
      },
      "outputs": [],
      "source": [
        "# Install YoloV5\n",
        "!cd yolov5\n",
        "!pip install -r requirements.txt  # install\n",
        "!pip install wandb\n",
        "import torch\n",
        "import utils\n",
        "import datetime\n",
        "import wandb, os\n",
        "!cd ..\n",
        "current_datetime = datetime.datetime.now()\n",
        "formatted_datetime = current_datetime.strftime(\"%d-%m-%Y\")\n",
        "display = utils.notebook_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e1ee9d",
      "metadata": {
        "id": "52e1ee9d"
      },
      "outputs": [],
      "source": [
        "# View model WANDB\n",
        "!pip install wandb --upgrade  # Up\n",
        "os.environ[\"WANDB_API_KEY\"] = \"7df0deadbf0e37559c5ad5b7f6ed5a08320c32dc\"\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning model\n",
        "wandb.init(project=\"Target_Robocon24_Detection\")\n",
        "!python /content/yolov5/train.py --img 640 --batch 16 --epochs 100 --data /content/data/data.yaml --weights yolov5s.pt --cache --hyp /content/hyp.scratch-low.yaml\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "gaE5dJg4C0YN"
      },
      "id": "gaE5dJg4C0YN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/segment/predict.py --source 0 --weights /content/yolov5/runs/train/exp5/weights/best.pt --img 640 --half"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMNkitu4cjQc",
        "outputId": "8ea8cb31-16f5-405b-c2eb-39a10605dea7"
      },
      "id": "pMNkitu4cjQc",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1msegment/predict: \u001b[0mweights=['/content/yolov5/runs/train/exp5/weights/best.pt'], source=0, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/predict-seg, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=True, dnn=False, vid_stride=1, retina_masks=False\n",
            "YOLOv5 üöÄ v7.0-371-g6629839d Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "WARNING ‚ö†Ô∏è Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "[ WARN:0@3.556] global cap_v4l.cpp:999 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
            "[ERROR:0@3.556] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/segment/predict.py\", line 307, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/segment/predict.py\", line 302, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/segment/predict.py\", line 124, in run\n",
            "    dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 463, in __init__\n",
            "    assert cap.isOpened(), f\"{st}Failed to open {s}\"\n",
            "AssertionError: 1/1: 0... Failed to open 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aiHOP_qbc72S"
      },
      "id": "aiHOP_qbc72S",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}